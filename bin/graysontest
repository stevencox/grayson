#!/usr/bin/env python

''' Grayson unit tests. '''
import glob
import json
import logging
import unittest
import xmlrunner
import shutil
import os
import re
import sys
import traceback

from grayson.packager import GraysonPackager
from grayson.compiler.compiler import GraysonCompiler
from grayson.compiler.exception import CycleException
from grayson.executor import Executor
from grayson.common.util import GraysonUtil

from Pegasus.DAX3 import ADAG
from Pegasus.DAX3 import DAX
from Pegasus.DAX3 import Executable
from Pegasus.DAX3 import File
from Pegasus.DAX3 import Job
from Pegasus.DAX3 import Link
from Pegasus.DAX3 import PFN
from Pegasus.DAX3 import Profile
from Pegasus.DAX3 import Transformation
import Pegasus.DAX3

logger = logging.getLogger (__name__)
broken = False

''' Basic test case '''
class GraysonTestCase (unittest.TestCase):

    def setUp (self):
        self.outputDir = "target"
        self.invocations = {
            'alpha' : {
                "model"     : "alpha-context.graphml",
                "modelPath" : [ self.getSamplePath ("alpha") ],
                "verify"    : {
                    # ========================
                    # == Nucleosome Test
                    # ========================
                    'alpha.dax' :
"""dax name: <alpha>
files:
   file: <input.txt>
      pfn: <file://target/alpha/input.txt>
   file: <one.out>
      pfn: <file://target/alpha/work/outputs/one.out>
   file: <two.out>
      pfn: <file://target/alpha/work/outputs/two.out>
jobs:
   job: <one>, id: <1n1> namespace: <alpha> version: <None>
      usedfile: <input.txt>
      usedfile: <one.out>
   job: <two>, id: <1n3> namespace: <alpha> version: <None>
      usedfile: <one.out>
      usedfile: <two.out>
transformations:
executables:
   executable: <one> namespace: <alpha>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/alpha/bin/alpha.sh>
   executable: <two> namespace: <alpha>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/alpha/bin/alpha.sh>
dependencies:
   dependency: <1n3>
      parent: parent=><one> edge_label=><None>"""
                    }
                },
            'nucleosome' : {
                "model"     : "blueridge-nucleosome-context.graphml",
                "modelPath" : [ self.getSamplePath (os.path.join ("amber", "nucleosome")),
                                "samples" ],
                "verify"    : {
                    # ========================
                    # == Nucleosome Test
                    # ========================
                    'nucleosome.dax' : ''
"""dax name: <nucleosome>
files:
   file: <prmtop>
      pfn: <file://target/nucleosome/work/outputs/prmtop>
   file: <minimization.mdin>
      pfn: <file://target/nucleosome/work/outputs/minimization.mdin>
   file: <restart.min>
      pfn: <file://target/nucleosome/work/outputs/restart.min>
   file: <restrt>
      pfn: <file://target/nucleosome/work/outputs/restrt>
   file: <min.out>
      pfn: <file://target/nucleosome/work/outputs/min.out>
   file: <logfile>
      pfn: <file://target/nucleosome/work/outputs/logfile>
   file: <heatsystem.1.mdin>
      pfn: <file://target/nucleosome/work/outputs/heatsystem.1.mdin>
   file: <dyn1.out>
      pfn: <file://target/nucleosome/work/outputs/dyn1.out>
   file: <restart.1>
      pfn: <file://target/nucleosome/work/outputs/restart.1>
   file: <heatsystem.2.mdin>
      pfn: <file://target/nucleosome/work/outputs/heatsystem.2.mdin>
   file: <dyn2.out>
      pfn: <file://target/nucleosome/work/outputs/dyn2.out>
   file: <restart.2>
      pfn: <file://target/nucleosome/work/outputs/restart.2>
jobs:
   job: <minimization>, id: <1n2> namespace: <nucleosome> version: <None>
      usedfile: <restart.min>
      usedfile: <prmtop>
      usedfile: <minimization.mdin>
      usedfile: <min.out>
      usedfile: <logfile>
      usedfile: <restrt>
         profile: namespace:<globus> key:<xcount> value:<8>
         profile: namespace:<globus> key:<maxWallTime> value:<2800>
         profile: namespace:<globus> key:<jobType> value:<single>
         profile: namespace:<globus> key:<host_xcount> value:<1>
   job: <dynamics-1>, id: <1n5> namespace: <nucleosome> version: <None>
      usedfile: <heatsystem.1.mdin>
      usedfile: <restrt>
      usedfile: <prmtop>
      usedfile: <restart.1>
      usedfile: <logfile>
      usedfile: <dyn1.out>
      usedfile: <restrt>
         profile: namespace:<globus> key:<queue> value:<gpgpu>
         profile: namespace:<globus> key:<xcount> value:<8>
         profile: namespace:<globus> key:<jobType> value:<single>
         profile: namespace:<globus> key:<maxWallTime> value:<2800>
         profile: namespace:<globus> key:<host_xcount> value:<1>
   job: <dynamics-2>, id: <1n6> namespace: <nucleosome> version: <None>
      usedfile: <restart.2>
      usedfile: <heatsystem.2.mdin>
      usedfile: <prmtop>
      usedfile: <restrt>
      usedfile: <logfile>
      usedfile: <dyn2.out>
         profile: namespace:<globus> key:<queue> value:<gpgpu>
         profile: namespace:<globus> key:<xcount> value:<8>
         profile: namespace:<globus> key:<jobType> value:<single>
         profile: namespace:<globus> key:<maxWallTime> value:<2800>
         profile: namespace:<globus> key:<host_xcount> value:<1>
transformations:
executables:
   executable: <minimization> namespace: <nucleosome>, version: <None>, arch: <None>, os: <linux>
      pfn: <file:///home/scox/gpu/bin/pmemd.MPI>
   executable: <dynamics-1> namespace: <nucleosome>, version: <None>, arch: <None>, os: <linux>
      pfn: <file:///home/scox/gpu/bin/pmemd.cuda.MPI>
   executable: <dynamics-2> namespace: <nucleosome>, version: <None>, arch: <None>, os: <linux>
      pfn: <file:///home/scox/gpu/bin/pmemd.cuda.MPI>
dependencies:
   dependency: <1n5>
      parent: parent=><minimization> edge_label=><None>
   dependency: <1n6>
      parent: parent=><dynamics-1> edge_label=><None>"""

                    }
                },
            'blackdiamond' : {
                "model"     : "blackdiamond-local-context.graphml",
                "modelPath" : [ self.getSamplePath ("blackdiamond") ],
                "verify"    : {
                    
                    # ========================
                    # == Blackdiamond Test
                    # ========================
                    'blackdiamond.dax' :

"""dax name: <blackdiamond>
files:
   file: <f.b1>
      pfn: <file://target/blackdiamond/work/outputs/f.b1>
   file: <f.c1>
      pfn: <file://target/blackdiamond/work/outputs/f.c1>
   file: <f.b2>
      pfn: <file://target/blackdiamond/work/outputs/f.b2>
   file: <f.c2>
      pfn: <file://target/blackdiamond/work/outputs/f.c2>
   file: <f.a>
      pfn: <file://target/blackdiamond/work/outputs/f.a>
   file: <f.d>
      pfn: <file://target/blackdiamond/work/outputs/f.d>
jobs:
   job: <findrange.1>, id: <1n2> namespace: <blackdiamond> version: <None>
      usedfile: <f.b1>
      usedfile: <f.c1>
   job: <findrange.2>, id: <1n3> namespace: <blackdiamond> version: <None>
      usedfile: <f.b2>
      usedfile: <f.c2>
   job: <preprocess>, id: <1n4> namespace: <blackdiamond> version: <None>
      usedfile: <f.a>
      usedfile: <f.b2>
      usedfile: <f.b1>
   job: <analyze>, id: <1n5> namespace: <blackdiamond> version: <None>
      usedfile: <f.c1>
      usedfile: <f.c2>
      usedfile: <f.d>
transformations:
executables:
   executable: <findrange.1> namespace: <blackdiamond>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/blackdiamond/bin/keg>
   executable: <findrange.2> namespace: <blackdiamond>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/blackdiamond/bin/keg>
   executable: <preprocess> namespace: <blackdiamond>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/blackdiamond/bin/keg>
   executable: <analyze> namespace: <blackdiamond>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/blackdiamond/bin/keg>
dependencies:
   dependency: <1n5>
      parent: parent=><findrange.1> edge_label=><None>
      parent: parent=><findrange.2> edge_label=><None>
   dependency: <1n2>
      parent: parent=><preprocess> edge_label=><None>
   dependency: <1n3>
      parent: parent=><preprocess> edge_label=><None>"""
                    },
                },
            'lambda' : {
                "model" : "test-context.graphml",
                "modelPath" : [
                    self.getSamplePath ("lambda"),
                    "samples" ],
                "define" : { "data" : os.path.realpath (os.path.join ("samples", "lambda", "data")) },
                "verify" : {

                    # ========================
                    # == Lambda Uber Test
                    # ========================
                    "lambda-uber.dax" : 

"""dax name: <lambda-uber>
files:
   file: <input-one.tar.gz>
      pfn: <file://target/lambda/work/input-one.tar.gz>
   file: <input-two.tar.gz>
      pfn: <file://target/lambda/work/input-two.tar.gz>
   file: <report.txt>
      pfn: <file://target/lambda/work/outputs/report.txt>
jobs:
   job: <package>, id: <1n4> namespace: <lambda-uber> version: <None>
      usedfile: <input-one.tar.gz>
      usedfile: <input-two.tar.gz>
   job: <merge>, id: <1n6> namespace: <lambda-uber> version: <None>
      usedfile: <report.txt>
   dax-job: <wind.0.dax>
      usedfile: <input-one.tar.gz>
      usedfile: <input-two.tar.gz>
transformations:
executables:
   executable: <package> namespace: <lambda-uber>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/lambda/bin/package.sh>
   executable: <merge> namespace: <lambda-uber>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/lambda/bin/merge.sh>
dependencies:
   dependency: <1n6>
      parent: parent=><wind.0.dax> edge_label=><None>
   dependency: <ID0000001>
      parent: parent=><package> edge_label=><None>""",


                    # ========================
                    # == Lambda Flow 0 Test
                    # ========================
                    'lambda-flow.0.dax' : 

"""dax name: <lambda-flow.0>
files:
   file: <a.22.tar.gz-0-out.tar.gz>
      pfn: <file://target/lambda/work/outputs/a.22.tar.gz-0-out.tar.gz>
   file: <input-one.tar.gz>
      pfn: <file://target/lambda/work/outputs/input-one.tar.gz>
   file: <input-two.tar.gz>
      pfn: <file://target/lambda/work/outputs/input-two.tar.gz>
   file: <a.22.tar.gz>
      pfn: <file:///.*/samples/lambda/data/a.22.tar.gz>
jobs:
   job: <lambda>, id: <1n2> namespace: <lambda-flow.0> version: <None>
      usedfile: <a.22.tar.gz>
      usedfile: <input-one.tar.gz>
      usedfile: <input-two.tar.gz>
      usedfile: <a.22.tar.gz-0-out.tar.gz>
   dax-job: <quality-check.0.dax>
      usedfile: <a.22.tar.gz-0-out.tar.gz>
      usedfile: <a.22.tar.gz-0-out.tar.gz>
transformations:
executables:
   executable: <lambda> namespace: <lambda-flow.0>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/lambda/bin/lambda.sh>
dependencies:
   dependency: <ID0000001>
      parent: parent=><lambda> edge_label=><None>""",



                    # ========================
                    # == Lambda Flow 0 Test
                    # ========================
                    'lambda-flow.20.dax' : ''
"""dax name: <lambda-flow.20>
files:
   file: <c.22.tar.gz-6-out.tar.gz>
      pfn: <file://target/lambda/work/outputs/c.22.tar.gz-6-out.tar.gz>
   file: <input-one.tar.gz>
      pfn: <file://target/lambda/work/outputs/input-one.tar.gz>
   file: <input-two.tar.gz>
      pfn: <file://target/lambda/work/outputs/input-two.tar.gz>
   file: <c.22.tar.gz>
      pfn: <file:///.*/samples/lambda/data/c.22.tar.gz>
   file: <c.22.tar.gz-5-out.tar.gz>
      pfn: <file://target/lambda/work/outputs/c.22.tar.gz-5-out.tar.gz>
jobs:
   job: <lambda>, id: <1n2> namespace: <lambda-flow.20> version: <None>
      usedfile: <input-one.tar.gz>
      usedfile: <c.22.tar.gz-5-out.tar.gz>
      usedfile: <c.22.tar.gz>
      usedfile: <input-two.tar.gz>
      usedfile: <c.22.tar.gz-6-out.tar.gz>
   dax-job: <quality-check.20.dax>
      usedfile: <c.22.tar.gz-6-out.tar.gz>
      usedfile: <c.22.tar.gz-6-out.tar.gz>
transformations:
executables:
   executable: <lambda> namespace: <lambda-flow.20>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/lambda/bin/lambda.sh>
dependencies:
   dependency: <ID0000001>
      parent: parent=><lambda> edge_label=><None>""",


                    # ========================
                    # == Quality Check 0 Test
                    # ========================
                    'quality-check.0.dax' :

"""dax name: <quality-check.0>
files:
   file: <a.22.tar.gz-0-out.tar.gz>
      pfn: <file://target/lambda/work/outputs/a.22.tar.gz-0-out.tar.gz>
jobs:
   job: <check>, id: <1n1> namespace: <quality-check.0> version: <None>
      usedfile: <a.22.tar.gz-0-out.tar.gz>
transformations:
executables:
   executable: <check> namespace: <quality-check.0>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/lambda/bin/check.sh>
dependencies:""",

                    # ========================
                    # == Quality Check 20 Test
                    # ========================
                    'quality-check.20.dax' : 

"""dax name: <quality-check.20>
files:
   file: <c.22.tar.gz-6-out.tar.gz>
      pfn: <file://target/lambda/work/outputs/c.22.tar.gz-6-out.tar.gz>
jobs:
   job: <check>, id: <1n1> namespace: <quality-check.20> version: <None>
      usedfile: <c.22.tar.gz-6-out.tar.gz>
transformations:
executables:
   executable: <check> namespace: <quality-check.20>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/lambda/bin/check.sh>
dependencies:""",

                    }
                },

            'scan' : {
                "model"     : "scan-test-context.graphml",
                "modelPath" : [ self.getSamplePath ("scan") ],
                "define"    : { "chunk" : 0 },
                "verify"    : {
                    # ========================
                    # == Scan Test
                    # ========================
                    'scan-uber.dax' :
"""dax name: <scan-uber>
files:
   file: <full-sifs.txt>
      pfn: <file://target/scan/work/outputs/full-sifs.txt>
   file: <database.txt>
      pfn: <file://target/scan/work/outputs/database.txt>
   file: <matrix.txt>
      pfn: <file://target/scan/work/outputs/matrix.txt>
   file: <adjacency.txt>
      pfn: <file://target/scan/work/outputs/adjacency.txt>
   file: <score.x>
      pfn: <file://target/scan/bin/score.x>
   file: <fasta-chunks.tar.gz>
      pfn: <file://target/scan/work/outputs/fasta-chunks.tar.gz>
   file: <fasta.txt>
      pfn: <file://target/scan/input/fasta.txt>
jobs:
   job: <score>, id: <1n2> namespace: <scan-uber> version: <None>
      usedfile: <full-sifs.txt>
      usedfile: <score.x>
      usedfile: <adjacency.txt>
      usedfile: <database.txt>
      usedfile: <matrix.txt>
   job: <prepare>, id: <1n9> namespace: <scan-uber> version: <None>
      usedfile: <fasta.txt>
      usedfile: <fasta-chunks.tar.gz>
   job: <reduce>, id: <1n10> namespace: <scan-uber> version: <None>
      usedfile: <full-sifs.txt>
   job: <map>, id: <1n12.synth> namespace: <scan-uber> version: <None>
      usedfile: <fasta-chunks.tar.gz>
      usedfile: <fasta-chunks.tar.gz>
         profile: namespace:<env> key:<PYTHONPATH> value:<.*>
         profile: namespace:<env> key:<GRAYSON_HOME> value:<.*>
         profile: namespace:<env> key:<GLOBUS_LOCATION> value:<.*>
         profile: namespace:<env> key:<CONDOR_HOME> value:<.*>
         profile: namespace:<env> key:<PATH> value:<.*
         profile: namespace:<env> key:<LD_LIBRARY_PATH> value:<.*>
   dax-job: <scan-flow.dax>
      usedfile: <fasta-chunks.tar.gz>
transformations:
executables:
   executable: <score> namespace: <scan-uber>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/scan/bin/score.sh>
   executable: <prepare> namespace: <scan-uber>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/scan/bin/prepare.sh>
   executable: <reduce> namespace: <scan-uber>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://target/scan/bin/reduce.sh>
   executable: <map> namespace: <scan-uber>, version: <None>, arch: <None>, os: <linux>
      pfn: <file://.*/bin/graysonc>
dependencies:
   dependency: <1n10>
      parent: parent=><scan-flow.dax> edge_label=><None>
   dependency: <1n12.synth>
      parent: parent=><prepare> edge_label=><None>
   dependency: <1n2>
      parent: parent=><reduce> edge_label=><None>
   dependency: <ID0000001>
      parent: parent=><map> edge_label=><None>
      parent: parent=><prepare> edge_label=><None>"""

                    }
                },

            'namd' : {
                "model"     : "nersc-dirac-context.graphml",
                "modelPath" : [ 'samples', self.getSamplePath ("namd") ],
                "define"    : { "userName" : "username"},
                "verify"    : {
                    # ========================
                    # == NAMD Test
                    # ========================
                    'namd-uber.dax' :
"""dax name: <namd-uber>
files:
jobs:
   dax-job: <map.0.dax>
transformations:
executables:
dependencies:""",
                    'namd-flow.0.dax' : 
"""dax name: <namd-flow.0>
files:
   file: <beratan-0.tar.gz>
      pfn: <http://ci-dev.renci.org/nexus/service/local/repo_groups/Autobuild-RENCI/content/org/renci/duke/chemistry/beratan-0.tar.gz>
   file: <namd.tar.gz>
      pfn: <http://ci-dev.renci.org/nexus/service/local/repo_groups/Autobuild-RENCI/content/org/renci/namd/2.8-linux-x86_64-CUDA/namd.tar.gz>
   file: <mpich2-static-1.1.1p1.tar.gz>
      pfn: <http://ci-dev.renci.org/nexus/service/local/repo_groups/Autobuild-RENCI/content/org/renci/mpich2-static/1.1.1p1//mpich2-static-1.1.1p1.tar.gz>
   file: <out-0.tar.gz>
      pfn: <gsiftp://.*/namd/work/outputs/out-0.tar.gz>
   file: <cpuinfo>
      pfn: <.*/namd/bin/cpuinfo>
jobs:
   job: <namd>, id: <1n3> namespace: <namd-flow.0> version: <None>
      usedfile: <mpich2-static-1.1.1p1.tar.gz>
      usedfile: <cpuinfo>
      usedfile: <beratan-0.tar.gz>
      usedfile: <namd.tar.gz>
      usedfile: <out-0.tar.gz>
         profile: namespace:<globus> key:<queue> value:<dirac_reg>
         profile: namespace:<globus> key:<xcount> value:<8:fermi>
         profile: namespace:<globus> key:<maxWallTime> value:<240>
         profile: namespace:<globus> key:<jobType> value:<mpi>
         profile: namespace:<globus> key:<host_xcount> value:<1>
         profile: namespace:<condor> key:<x509userproxy> value:<.*/var/proxy/x509_proxy_username>
transformations:
executables:
   executable: <namd> namespace: <namd-flow.0>, version: <None>, arch: <x86_64>, os: <linux>
      pfn: <.*/namd/bin/namd.sh>
dependencies:""",
                    'map.0.dax' :
"""dax name: <map.0.dax>
files:
jobs:
   dax-job: <namd-flow.0.dax>
   dax-job: <namd-flow.1.dax>
   dax-job: <namd-flow.2.dax>
transformations:
executables:
dependencies:
   dependency: <ID0000003>
      parent: parent=><namd-flow.1.dax> edge_label=><None>
   dependency: <ID0000002>
      parent: parent=><namd-flow.0.dax> edge_label=><None>"""

                    }
                }
            }

    def getOutputFile (self, fileName):
        return os.path.join (self.outputDir, fileName)

    def getSamplePath (self, sample):
        if type (sample) == list:
            sample = os.path.join (sample)
        return os.path.join ("samples", sample, "model")

class GraysonCompilerTests (GraysonTestCase):

    def setUp (self):
        super(GraysonCompilerTests, self).setUp ()

    def areEqual (self, A, B, skip=[]):
        equal = True
        for key in A:
            if not key in skip:
                value = A [key]
                other = B [key]
                equal = self.areEqual (value, other) if isinstance (value, dict) else value == other
                if not equal:
                    break
        return equal

    def output (self, text):
        print text
        logger.info (text)

    def do_test_model (self, test_name):
        #test_name = test_case ["name"]
        test_case = self.invocations [test_name]
        models = [ test_case ["model"] ]
        modelPath = test_case ["modelPath"]
        inputProperties={}
        if "define" in test_case:
            inputProperties = test_case ["define"]
            
        banner = """
        ========================================================================
        == P A C K A G E                                                        
        ==             test: (%s)
        ==            model: (%s)
        ==             path: (%s)
        == input-properties: (%s)
        ========================================================================""" % (
            test_name, models, modelPath, inputProperties)

        self.output (banner)
        outputPath = os.path.join (self.outputDir, test_name)
        GraysonCompiler.compile (models = models,
                                 modelPath = modelPath,
                                 outputdir = outputPath,
                                 logLevel = "debug",
                                 modelProperties = inputProperties,
                                 output=models[0].replace (".graphml", ".dax"),
                                 packaging = True)
        banner = """
        ========================================================================
        == C O M P I L E                                                        
        ==             test: (%s)
        ==            model: (%s)
        ==             path: (%s)
        == input-properties: (%s)
        =========================================================================""" % (
            test_name, models, modelPath, inputProperties)

        self.output (banner)
        modelName = models[0].replace (".graphml", ".grayson")
        modelName = os.path.join (outputPath, os.path.basename (modelName))
        models[0] = modelName
        GraysonCompiler.compile (models = models,
                                 outputdir = outputPath,
                                 output=models[0].replace (".grayson", ".dax"),
                                 toLogFile="%s/%s" % (outputPath, "log.txt") )
                                 
        if "verify" in test_case:
            verification = test_case ["verify"]
            for filename in verification:
                output_workflow = os.path.join (outputPath, filename)
                baseline = verification [filename]
                self.verify_compiler_output (output_workflow, baseline.rstrip ())

                
    def bufferlog (self, buffer, text):
        self.output (text)
        buffer.append (text)

    def verify_compiler_output (self, output_workflow, baseline=None):
        buffer = []
        banner = """\n
==============================================
== A N A L Y Z E                              
==    output: %s
==============================================\n
""" % output_workflow
        self.output (banner)
        dag = Pegasus.DAX3.parse (output_workflow)
        self.bufferlog (buffer, "dax name: <%s>" % dag.name)
        self.bufferlog (buffer, "files:")
        for file in dag.files:
            self.bufferlog (buffer, "   file: <%s>" % file.name)
            for pfn in file.pfns:
                self.bufferlog (buffer, "      pfn: <%s>" % pfn.url)
                for profile in pfn.profiles:
                    self.bufferlog (buffer, "         profile: namespace:<%s> key:<%s> value:<%s>" % (profile.namespace, profile.key, profile.value))
        self.bufferlog (buffer, "jobs:")
        for job in dag.jobs:
            if isinstance (job, DAX):
                self.bufferlog (buffer, "   dax-job: <%s>" % job.file)
            else:
                self.bufferlog (buffer, "   job: <%s>, id: <%s> namespace: <%s> version: <%s>" % ( job.name, job.id, job.namespace, job.version))
            for file in job.used_files:
                self.bufferlog (buffer, "      usedfile: <%s>" % file.name)
            for profile in job.profiles:
                self.bufferlog (buffer, "         profile: namespace:<%s> key:<%s> value:<%s>" % (profile.namespace, profile.key, profile.value))
        self.bufferlog (buffer, "transformations:")
        for trans in dag.transformations:
            self.bufferlog (buffer, "   transformation: <%s> namespace: <%s>, version: <%s>" % (trans.name, trans.namespace, trans.version))
            for use in trans.used_files:
                self.bufferlog (buffer, "       uses: <%s>" % use.name)
        self.bufferlog (buffer, "executables:")
        for exe in dag.executables:
            self.bufferlog (buffer, "   executable: <%s> namespace: <%s>, version: <%s>, arch: <%s>, os: <%s>" % ( exe.name, exe.namespace, exe.version, exe.arch, exe.os))
            for pfn in exe.pfns:
                self.bufferlog (buffer, "      pfn: <%s>" % pfn.url)
                for profile in pfn.profiles:
                    self.bufferlog (buffer, "         profile: namespace:<%s> key:<%s> value:<%s>" % (profile.namespace, profile.key, profile.value))
        self.bufferlog (buffer, "dependencies:")
        for dep in dag.dependencies:
            self.bufferlog (buffer, "   dependency: <%s>" % dep.child.id)
            for parent in dep.parents:
                job = parent [0]
                name = job.file if isinstance (job, DAX) else job.name
                self.bufferlog (buffer, "      parent: parent=><%s> edge_label=><%s>" % ( name, parent[1]))
        actual = '\n'.join (buffer).rstrip ()
        try:
            if re.search (baseline, actual):
                matched = """
======================================================
== *** Actual output matched baseline expectations  ==
======================================================
"""
                self.output (matched)
            else:
                broken = True
                raise ValueError ('Expected Baseline Output: \n[%s] \nReceived Actual Output: \n[%s]' % (baseline, actual))

        except Exception as e:
            error = """
_____________E_R_R_O_R______________________________________\n%s\n_____________E_R_R_O_R______________________________________
""" % baseline
            self.output (error)
            raise e

    def tearDown (self):
        pass

class GraysonAlphaTest (GraysonCompilerTests):
    def setUp (self):
        super (GraysonAlphaTest, self).setUp ()
    def test_alpha (self):
        self.do_test_model ("alpha")

class GraysonNucleosomeTest (GraysonCompilerTests):
    def setUp (self):
        super (GraysonNucleosomeTest, self).setUp ()
    def test_nucleosome (self):
        self.do_test_model ("nucleosome")

class GraysonBlackdiamondTest (GraysonCompilerTests):
    def setUp (self):
        super (GraysonBlackdiamondTest, self).setUp ()
    def test_blackdiamond (self):
        self.do_test_model ("blackdiamond")

class GraysonLambdaTest (GraysonCompilerTests):
    def setUp (self):
        super (GraysonLambdaTest, self).setUp ()
    def test_lambda (self):
        self.do_test_model ("lambda")

class GraysonScanTest (GraysonCompilerTests):
    def setUp (self):
        super (GraysonScanTest, self).setUp ()
    def test_scan (self):
        test_name = "scan"
        self.do_test_model (test_name)
        config = os.path.join (self.outputDir, test_name, "map.grayconf")
        generatedObj = json.loads (GraysonUtil.readFile (config))
        expectedObj = {
            "outputName": "scan-flow", 
            "modelPath": "target/scan:target/scan:", 
            "operator": {
                "index": "chunk", 
                "version": "1.0", 
                "variable": "file", 
                "input": "fasta-chunks.tar.gz", 
                "flow": "scan-flow.graphml", 
                "namespace": "scan-flow", 
                "type": "dynamicMap", 
                "method": "tar"
                },
            "graysonHome": "/home/scox/dev/grayson", 
            "appHome": "target/scan", 
            "outputDir": "/home/scox/dev/grayson/target/scan", 
            "contextModels": "scan-test-core-context.graphml:scan-executable-context.graphml", 
            "sites": "local"
            }
        self.compareConfs (expectedObj, generatedObj)

        #self.assertTrue (self.areEqual (expectedObj, generatedObj, [ 'graysonHome' ]))
        logger.info ("Verified generated map operator configuration: \n%s", json.dumps (generatedObj, indent=4))

    def compareConfs (self, L, R):
        fields = {
            "top" : [
                "outputName",
                "modelPath",
                #"graysonHome", machine dependent
                "appHome",
                #"outputDir", machine dependent
                "sites" ],
            "operator" : [
                "index",
                "version",
                "variable",
                "input",
                "flow",
                "namespace",
                "type",
                "method" ]
        }
        self.compareObj (L, R, fields ['top'])
        self.compareObj (L, R, fields ['operator'])

    def compareObj (self, L, R, fields):
        for field in fields:
            logger.info ("comparing map operator field: %s", field)
            self.areEqual (L, R, [ field ])

class GraysonNAMDTest (GraysonCompilerTests):
    def setUp (self):
        super (GraysonNAMDTest, self).setUp ()
    def test_namd (self):
        self.do_test_model ("namd")


class GraysonCycleDetectionTests (GraysonTestCase):

    def setUp (self):
        super (GraysonCycleDetectionTests, self).setUp ()

    def test_cycle_detection (self):        
        banner = """
====================================
== C Y C L E   D E T E C T I O N  ==
===================================="""
        logger.info (banner)
        print banner
        testName = "detect-cycle"
        model = "%s.graphml" % testName
        outputPath = os.path.join (self.outputDir, testName)
        with self.assertRaises (CycleException):
            GraysonCompiler.compile (models    = [ model ],
                                     modelPath = [ self.getSamplePath ("test") ],
                                     outputdir = outputPath,
                                     output    = model.replace (".graphml", ".dax")) 
                           
class GraysonUITests (GraysonTestCase):

    def setUp (self):
        super(GraysonUITests, self).setUp ()

    def test_ui (self):
        print "+======================================== %s" % len (sys.argv)
        if len (sys.argv) > 1 and sys.argv[1] == '--ui':
            context = {
                'GRAYSON_HOME' : os.environ ['GRAYSON_HOME'],
                'PHANTOMJS_HOME' : os.environ ['PHANTOMJS_HOME']
                }

            def processor (line):
                print " ||- %s" % line.rstrip ()

            executor = Executor (context)
            try:
                command = "$PHANTOMJS_HOME/bin/phantomjs $GRAYSON_HOME/web/graysonapp/static/js/test/phantomjs-qunit-headless.js"
                if len (sys.argv) == 5:
                    command = "%s %s %s %s" % (
                        command,
                        sys.argv [2],
                        sys.argv [3],
                        sys.argv [4])
                executor.execute (command   = command,
                                  pipe      = True,
                                  processor = processor);
            except ValueError as e:
                traceback.print_exc ()

if __name__ == '__main__':
    
    suite = []
    testClasses = [
        GraysonCycleDetectionTests,
        GraysonAlphaTest,
        GraysonBlackdiamondTest,
        GraysonNucleosomeTest,
        GraysonLambdaTest,
        GraysonNAMDTest,
        GraysonScanTest,
        GraysonUITests 
        ]
    loader = unittest.TestLoader ()
    logger.info ("Initializing test classes.")
    for testClass in testClasses:
        suite.append (loader.loadTestsFromTestCase (testClass))

    for test in suite:
        unittest.TextTestRunner (verbosity=2).run (test)    
        for t in test:
            try:
                output = None
                try:
                    name = ("%s" % t).split (' ')[0]
                    output = open ("TEST-%s.xml" % name, "w")
                    runner = xmlrunner.XMLTestRunner (output).run (t)
                    if broken:
                        break
                finally:
                    if output:
                        output.close ()
            except IOError as e:
                logger.error (e)

